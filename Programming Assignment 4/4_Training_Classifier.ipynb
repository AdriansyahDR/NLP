{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Try different classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"Data/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"Data/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"Data/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"Data/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"Data/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {1:'Logistic Regression',\n",
    "          2:'Multinomial Naive Bayes', \n",
    "          3:'K Nearest Neighbour', \n",
    "          4:'Support Vector Machines', \n",
    "          5:'Random Forest'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use in Random Forest:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 8,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Pilihan jenis classifier. Untuk selain nomor 1, maka perlu penyesuaian di bagian Random Search dan Grid Search.\n",
    "\n",
    "choice = 5\n",
    "\n",
    "if choice == 1:\n",
    "    classifier = LogisticRegression(random_state = 8)\n",
    "    print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "    pprint(classifier.get_params())\n",
    "elif choice==2:\n",
    "    classifier = MultinomialNB()\n",
    "    print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "    print(classifier)\n",
    "elif choice==3:\n",
    "    classifier =KNeighborsClassifier()\n",
    "    print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "    pprint(classifier.get_params())\n",
    "elif choice==4:\n",
    "    classifier =svm.SVC(random_state=8)\n",
    "    print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "    pprint(classifier.get_params())\n",
    "elif choice==5:\n",
    "    classifier = RandomForestClassifier(random_state = 8)\n",
    "    print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "    pprint(classifier.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cari parameter yang secara random menggunakan cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [20, 40, 60, 80, 100, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000]}\n"
     ]
    }
   ],
   "source": [
    "if choice == 1:\n",
    "    # Create the random grid logistic regression\n",
    "    random_grid = {'C': [float(x) for x in np.linspace(start = 0.1, stop = 1.9, num = 10)],\n",
    "               'multi_class': ['multinomial'],\n",
    "               'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "               'class_weight': ['balanced', None],\n",
    "               'penalty': ['l2']}\n",
    "elif choice==2:\n",
    "    pass\n",
    "elif choice==3:\n",
    "    pass\n",
    "elif choice==4:\n",
    "    # Create the random grid SVM\n",
    "    random_grid = {'C': [.0001, .001, .01],\n",
    "                  'kernel': ['linear', 'rbf', 'poly'],\n",
    "                  'gamma': [.0001, .001, .01, .1, 1, 10, 100],\n",
    "                  'degree': [1, 2, 3, 4, 5],\n",
    "                  'probability': [True]\n",
    "                 }\n",
    "elif choice==5:\n",
    "    # Create the random grid Random Forest\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [20, 40, 60, 80, 100, None],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]\n",
    "                     }\n",
    "    \n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [20, 40, 60, 80, 100,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=classifier,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9434181068095491\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'sag',\n",
       " 'penalty': 'l2',\n",
       " 'multi_class': 'multinomial',\n",
       " 'class_weight': 'balanced',\n",
       " 'C': 1.9}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian lanjutkan pencarian yang lebih detil terhadap daerah nilai terbaik hasil random search di atas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'C': [float(x) for x in np.linspace(start = 0.1, stop = 1.9, num = 10)],\n",
    "               'multi_class': ['multinomial'],\n",
    "               'solver': ['sag'],\n",
    "               'class_weight': ['balanced']}\n",
    "\n",
    "# Create a base model\n",
    "classifier = LogisticRegression(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   22.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.33, train_size=None),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=8, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 0.3, 0.5, 0.7, 0.8999999999999999,\n",
       "                               1.0999999999999999, 1.3, 1.5, 1.7, 1.9],\n",
       "                         'class_weight': ['balanced'],\n",
       "                         'multi_class': ['multinomial'], 'solver': ['sag']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=classifier, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'C': 1.9, 'class_weight': 'balanced', 'multi_class': 'multinomial', 'solver': 'sag'}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9701333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.9, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=8, solver='sag', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "best_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.9, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=8, solver='sag', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pred = best_classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>0.943114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Logistic Regression               0.987837           0.943114"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "     'Model': 'Logistic Regression',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_classifier.predict(features_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, classifier_pred)\n",
    "}\n",
    "\n",
    "df_models = pd.DataFrame(d, index=[0])\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        81\n",
      "           1       0.92      0.96      0.94        49\n",
      "           2       0.96      0.89      0.92        72\n",
      "           3       0.99      0.99      0.99        72\n",
      "           4       0.93      0.93      0.93        60\n",
      "\n",
      "    accuracy                           0.94       334\n",
      "   macro avg       0.94      0.94      0.94       334\n",
      "weighted avg       0.94      0.94      0.94       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,classifier_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aux_df = df[['Category', 'Category_Code']].drop_duplicates().sort_values('Category_Code')\n",
    "conf_matrix = confusion_matrix(labels_test, classifier_pred)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['Category'].values, \n",
    "            yticklabels=aux_df['Category'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandingkan performansi dengan base model, yaitu model dengan parameter default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9401197604790419"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = LogisticRegression(random_state = 8)\n",
    "base_model.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, base_model.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9431137724550899"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, best_classifier.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ubah format penyimpanan data ke CSV\n",
    "2. Coba buatkan feature berikut (save dan upload feature), lalu laporkan pengaruhnya terhadap akurasi klasifikasi:\n",
    "    a. Tanpa proses normalisation\n",
    "    b. Tanpa proses lemmatisation\n",
    "    c. Tanpa menghilangkan stopwords\n",
    "3. Coba buat tfidf dengan nilai \"max_features\" yang berbeda-beda (lebih besar dan lebih kecil dari 300), lalu laporkan pengaruhnya terhadap akurasi klasifikasi.\n",
    "4. Coba dengan beberapa algoritma klasifikasi yang berbeda (minimal 2 algoritma), carilah parameter terbaik (jelaskan nilai2 parameter yang telah dicoba untuk tiap jenis algoritma).\n",
    "5. Jika anda ingin menggunakan teks bahasa Indonesia, bagian mana saja yang perlu dilakukan penyesuaian?\n",
    "6. Opsional: Gunakan word embedding (e.g word2vec, GloVe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jawaban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban ditulis dalam sebuah laporan singkat format pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureLabelAwal():\n",
    "    # Dataframe\n",
    "    path_df = \"Data/df.pickle\"\n",
    "    with open(path_df, 'rb') as data:\n",
    "        df = pickle.load(data)\n",
    "\n",
    "    # features_train\n",
    "    path_features_train = \"Data/features_train.pickle\"\n",
    "    with open(path_features_train, 'rb') as data:\n",
    "        features_train = pickle.load(data)\n",
    "\n",
    "    # labels_train\n",
    "    path_labels_train = \"Data/labels_train.pickle\"\n",
    "    with open(path_labels_train, 'rb') as data:\n",
    "        labels_train = pickle.load(data)\n",
    "\n",
    "    # features_test\n",
    "    path_features_test = \"Data/features_test.pickle\"\n",
    "    with open(path_features_test, 'rb') as data:\n",
    "        features_test = pickle.load(data)\n",
    "\n",
    "    # labels_test\n",
    "    path_labels_test = \"Data/labels_test.pickle\"\n",
    "    with open(path_labels_test, 'rb') as data:\n",
    "        labels_test = pickle.load(data)\n",
    "        \n",
    "    return features_train, labels_train, features_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(ngram_range, min_df, max_df, max_features, path):\n",
    "    tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                            ngram_range=ngram_range,\n",
    "                            stop_words=None,\n",
    "                            lowercase=False,\n",
    "                            max_df=max_df,\n",
    "                            min_df=min_df,\n",
    "                            max_features=max_features,\n",
    "                            norm='l2',\n",
    "                            sublinear_tf=True)\n",
    "\n",
    "    features_train = tfidf.fit_transform(X_train).toarray()\n",
    "    labels_train = y_train\n",
    "    print(features_train.shape)\n",
    "\n",
    "    features_test = tfidf.transform(X_test).toarray()\n",
    "    labels_test = y_test\n",
    "    print(features_test.shape)\n",
    "    \n",
    "    # X_train\n",
    "    with open( path+'/X_train.pickle', 'wb') as output:\n",
    "        pickle.dump(X_train, output)\n",
    "\n",
    "    # X_test    \n",
    "    with open(path+'/X_test.pickle', 'wb') as output:\n",
    "        pickle.dump(X_test, output)\n",
    "\n",
    "    # y_train\n",
    "    with open(path+'/y_train.pickle', 'wb') as output:\n",
    "        pickle.dump(y_train, output)\n",
    "\n",
    "    # y_test\n",
    "    with open(path+'/y_test.pickle', 'wb') as output:\n",
    "        pickle.dump(y_test, output)\n",
    "\n",
    "    # df\n",
    "    with open(path+'/file.pickle', 'wb') as output:\n",
    "        pickle.dump(file, output)\n",
    "\n",
    "    # features_train\n",
    "    with open(path+'/features_train.pickle', 'wb') as output:\n",
    "        pickle.dump(features_train, output)\n",
    "\n",
    "    # labels_train\n",
    "    with open(path+'/labels_train.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_train, output)\n",
    "\n",
    "    # features_test\n",
    "    with open(path+'/features_test.pickle', 'wb') as output:\n",
    "        pickle.dump(features_test, output)\n",
    "\n",
    "    # labels_test\n",
    "    with open(path+'/labels_test.pickle', 'wb') as output:\n",
    "        pickle.dump(labels_test, output)\n",
    "\n",
    "    # TF-IDF object\n",
    "    with open(path+'/tfidf.pickle', 'wb') as output:\n",
    "        pickle.dump(tfidf, output)\n",
    "    \n",
    "    return features_train, labels_train, features_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {1:'Logistic Regression',\n",
    "          2:'Multinomial Naive Bayes', \n",
    "          3:'K Nearest Neighbour', \n",
    "          4:'Support Vector Machines', \n",
    "          5:'Random Forest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilihan jenis classifier. Untuk selain nomor 1, maka perlu penyesuaian di bagian Random Search dan Grid Search.\n",
    "def crossVal(choice): \n",
    "\n",
    "    if choice == 1:\n",
    "        classifier = LogisticRegression(random_state = 8)\n",
    "        print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "        pprint(classifier.get_params())\n",
    "        random_grid = {'C': [float(x) for x in np.linspace(start = 0.1, stop = 1.9, num = 10)],\n",
    "               'multi_class': ['multinomial'],\n",
    "               'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "               'class_weight': ['balanced', None],\n",
    "               'penalty': ['l2']}\n",
    "        \n",
    "    elif choice==2:\n",
    "        classifier = MultinomialNB()\n",
    "        print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "        print(classifier)\n",
    "    elif choice==3:\n",
    "        classifier =KNeighborsClassifier()\n",
    "        print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "        pprint(classifier.get_params())\n",
    "    elif choice==4:\n",
    "        classifier =svm.SVC(random_state=8)\n",
    "        print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "        pprint(classifier.get_params())\n",
    "        random_grid = {'C': [.0001, .001, .01],\n",
    "                  'kernel': ['linear', 'rbf', 'poly'],\n",
    "                  'gamma': [.0001, .001, .01, .1, 1, 10, 100],\n",
    "                  'degree': [1, 2, 3, 4, 5],\n",
    "                  'probability': [True]\n",
    "                 }\n",
    "    elif choice==5:\n",
    "        classifier = RandomForestClassifier(random_state = 8)\n",
    "        print('Parameters currently in use in {}:\\n'.format(models[choice]))\n",
    "        pprint(classifier.get_params())\n",
    "        random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [20, 40, 60, 80, 100, None],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]\n",
    "                     }\n",
    "    \n",
    "    # Definition of the random search\n",
    "    random_search = RandomizedSearchCV(estimator=classifier,\n",
    "                                       param_distributions=random_grid,\n",
    "                                       n_iter=50,\n",
    "                                       scoring='accuracy',\n",
    "                                       cv=3, \n",
    "                                       verbose=1, \n",
    "                                       random_state=8)\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(features_train, labels_train)\n",
    "    \n",
    "    print(\"The best hyperparameters from Random Search are:\")\n",
    "    print(random_search.best_params_)\n",
    "    print(\"\")\n",
    "    print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "    print(random_search.best_score_)\n",
    "    print(\"\")\n",
    "    \n",
    "    if choice == 1:\n",
    "        # Create the parameter grid based on the results of random search \n",
    "        param_grid = {'C': [float(x) for x in np.linspace(start = 0.1, stop = 1.9, num = 10)],\n",
    "                       'multi_class': [random_search.best_params_['multi_class']],\n",
    "                       'solver': [random_search.best_params_['solver']],\n",
    "                       'class_weight': [random_search.best_params_['class_weight']]}\n",
    "\n",
    "        # Create a base model\n",
    "        classifier = LogisticRegression(random_state=8)\n",
    "    \n",
    "    elif choice == 4:\n",
    "        param_grid = {'C': [.0001, .001, .01],\n",
    "                  'kernel': [random_search.best_params_['kernel']],\n",
    "                  'gamma': [random_search.best_params_['gamma']],\n",
    "                  'degree': [random_search.best_params_['degree']],\n",
    "                  'probability': [True]\n",
    "                 }\n",
    "        classifier = svm.SVC(random_state=8)\n",
    "        \n",
    "    elif choice == 5:\n",
    "        param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "               'max_features': [random_search.best_params_['max_features']],\n",
    "               'max_depth': [random_search.best_params_['max_depth']],\n",
    "               'min_samples_split': [random_search.best_params_['min_samples_split']],\n",
    "               'min_samples_leaf': [random_search.best_params_['min_samples_leaf']],\n",
    "               'bootstrap': [random_search.best_params_['bootstrap']]\n",
    "                     }\n",
    "        classifier = RandomForestClassifier(random_state=8)\n",
    "        \n",
    "    # Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "    cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=classifier, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=cv_sets,\n",
    "                               verbose=1)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(features_train, labels_train)\n",
    "    \n",
    "    print(\"The best hyperparameters from Grid Search are:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\")\n",
    "    print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "    print(grid_search.best_score_)\n",
    "    print(\"\")\n",
    "    \n",
    "    best_classifier = grid_search.best_estimator_\n",
    "    print(best_classifier)\n",
    "\n",
    "    return best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitandperform(features_train, labels_train, features_test, labels_test, best_classifier):\n",
    "    best_classifier.fit(features_train, labels_train)\n",
    "    classifier_pred = best_classifier.predict(features_test)\n",
    "    d = {\n",
    "     'Model': models[choice],\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_classifier.predict(features_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, classifier_pred)\n",
    "    }\n",
    "\n",
    "    df_models = pd.DataFrame(d, index=[0])\n",
    "    df_models\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(labels_test,classifier_pred))\n",
    "    print(\"\")\n",
    "    \n",
    "    base_model = classifier\n",
    "    base_model.fit(features_train, labels_train)\n",
    "    print('Accuracy Base Model = ',accuracy_score(labels_test, base_model.predict(features_test)))\n",
    "    \n",
    "    best_classifier.fit(features_train, labels_train)\n",
    "    print('Accuracy Best Classifier = ',accuracy_score(labels_test, best_classifier.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/bbc\\business\\001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/bbc\\business\\002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/bbc\\business\\003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/bbc\\business\\004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/bbc\\business\\005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   File_Name  Category  \\\n",
       "0  Data/bbc\\business\\001.txt  business   \n",
       "1  Data/bbc\\business\\002.txt  business   \n",
       "2  Data/bbc\\business\\003.txt  business   \n",
       "3  Data/bbc\\business\\004.txt  business   \n",
       "4  Data/bbc\\business\\005.txt  business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...              0  \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...              0  \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...              0  \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...              0  \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...              0  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df.to_csv (r'News_dataset.csv', index = False, header=True)\n",
    "file = pd.read_csv('News_dataset.csv')\n",
    "file['Content_Parsed'] = file['Content']\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adriansyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adriansyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Adriansyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')\n",
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delChar(file):\n",
    "    file['Content_Parsed'] = file['Content'].str.replace(\"\\r\", \" \")\n",
    "    file['Content_Parsed'] = file['Content_Parsed'].str.replace(\"\\n\", \" \")\n",
    "    file['Content_Parsed'] = file['Content_Parsed'].str.replace(\"    \", \" \")\n",
    "    file['Content_Parsed'] = file['Content_Parsed'].str.replace('\"', '')\n",
    "    return file\n",
    "\n",
    "def lower(file):\n",
    "    file['Content_Parsed'] = file['Content_Parsed'].str.lower()\n",
    "    return file\n",
    "\n",
    "def delPunct(file):\n",
    "    punctuation_signs = list(\"?:!.,;\")\n",
    "    file['Content_Parsed'] = file['Content_Parsed']\n",
    "\n",
    "    for punct_sign in punctuation_signs:\n",
    "        file['Content_Parsed'] = file['Content_Parsed'].str.replace(punct_sign, '')\n",
    "    \n",
    "    return file\n",
    "\n",
    "def delPossessivepron(file):\n",
    "    # Remove possessive pronouns\n",
    "    file['Content_Parsed'] = file['Content_Parsed'].str.replace(\"'s\", \"\")\n",
    "    return file\n",
    "\n",
    "def lemmatizer(file):\n",
    "    # Saving the lemmatizer into an object\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    nrows = len(file)\n",
    "    lemmatized_text_list = []\n",
    "\n",
    "    for row in range(0, nrows):\n",
    "\n",
    "        # Create an empty list containing lemmatized words\n",
    "        lemmatized_list = []\n",
    "\n",
    "        # Save the text and its words into an object\n",
    "        text = file.loc[row]['Content_Parsed']\n",
    "        text_words = text.split(\" \")\n",
    "\n",
    "        # Iterate through every word to lemmatize\n",
    "        for word in text_words:\n",
    "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "        # Join the list\n",
    "        lemmatized_text = \" \".join(lemmatized_list)\n",
    "\n",
    "        # Append to the list containing the texts\n",
    "        lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "    file['Content_Parsed'] = lemmatized_text_list\n",
    "    \n",
    "    return file\n",
    "\n",
    "def stopword(file):\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        file['Content_Parsed'] = file['Content_Parsed'].str.replace(regex_stopword, '')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use in Logistic Regression:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': 8,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'solver': 'sag', 'penalty': 'l2', 'multi_class': 'multinomial', 'class_weight': 'balanced', 'C': 1.9}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9587527985309285\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'C': 1.9, 'class_weight': 'balanced', 'multi_class': 'multinomial', 'solver': 'sag'}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9701333333333334\n",
      "LogisticRegression(C=1.9, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
      "                   penalty='l2', random_state=8, solver='sag', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Model untuk SOAL 2 dan 3 Logistic Regression\n",
    "choice = 1\n",
    "best_classifier = crossVal(choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a\n",
    "path = 'a'\n",
    "file.to_csv (r'datase_no_normalization.csv', index = False, header=True)\n",
    "file = pd.read_csv('News_dataset.csv')\n",
    "file['Content_Parsed'] = file['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1    Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2    Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3    High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4    Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "Name: Content_Parsed, dtype: object"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Content_Parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(file['Content_Parsed'], \n",
    "                                                    file['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = tf_idf(ngram_range, min_df, max_df, max_features, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        81\n",
      "           1       0.92      0.96      0.94        49\n",
      "           2       0.92      0.85      0.88        72\n",
      "           3       0.99      0.99      0.99        72\n",
      "           4       0.92      0.92      0.92        60\n",
      "\n",
      "    accuracy                           0.92       334\n",
      "   macro avg       0.92      0.92      0.92       334\n",
      "weighted avg       0.92      0.92      0.92       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.8952095808383234\n",
      "Accuracy Best Classifier =  0.9191616766467066\n"
     ]
    }
   ],
   "source": [
    "fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b\n",
    "path = 'b'\n",
    "file = pd.read_csv('News_dataset.csv')\n",
    "file['Content_Parsed'] = file['Content']\n",
    "file = delChar(file)\n",
    "file = lower(file)\n",
    "file = delPunct(file)\n",
    "file = delPossessivepron(file)\n",
    "file = stopword(file)\n",
    "file.to_csv (r'datase_no_lemmatization.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ad sales boost time warner profit  quarterly p...\n",
       "1    dollar gains  greenspan speech   dollar  hit  ...\n",
       "2    yukos unit buyer faces loan claim   owners  em...\n",
       "3    high fuel prices hit ba profits  british airwa...\n",
       "4    pernod takeover talk lifts domecq  shares  uk ...\n",
       "Name: Content_Parsed, dtype: object"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Content_Parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(file['Content_Parsed'], \n",
    "                                                    file['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = tf_idf(ngram_range, min_df, max_df, max_features, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        81\n",
      "           1       0.91      0.98      0.94        49\n",
      "           2       0.98      0.90      0.94        72\n",
      "           3       1.00      0.99      0.99        72\n",
      "           4       0.95      0.90      0.92        60\n",
      "\n",
      "    accuracy                           0.95       334\n",
      "   macro avg       0.95      0.95      0.95       334\n",
      "weighted avg       0.95      0.95      0.95       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9251497005988024\n",
      "Accuracy Best Classifier =  0.9461077844311377\n"
     ]
    }
   ],
   "source": [
    "fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2c\n",
    "path = 'c'\n",
    "file = pd.read_csv('News_dataset.csv')\n",
    "file['Content_Parsed'] = file['Content']\n",
    "file = delChar(file)\n",
    "file = lower(file)\n",
    "file = delPunct(file)\n",
    "file = delPossessivepron(file)\n",
    "file = lemmatizer(file)\n",
    "file.to_csv (r'datase_no_stopword.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ad sales boost time warner profit  quarterly p...\n",
       "1    dollar gain on greenspan speech  the dollar ha...\n",
       "2    yukos unit buyer face loan claim  the owners o...\n",
       "3    high fuel price hit ba profit  british airways...\n",
       "4    pernod takeover talk lift domecq  share in uk ...\n",
       "Name: Content_Parsed, dtype: object"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Content_Parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(file['Content_Parsed'], \n",
    "                                                    file['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = tf_idf(ngram_range, min_df, max_df, max_features, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        81\n",
      "           1       0.89      0.96      0.92        49\n",
      "           2       0.90      0.89      0.90        72\n",
      "           3       1.00      0.97      0.99        72\n",
      "           4       0.95      0.92      0.93        60\n",
      "\n",
      "    accuracy                           0.93       334\n",
      "   macro avg       0.93      0.93      0.93       334\n",
      "weighted avg       0.93      0.93      0.93       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.8892215568862275\n",
      "Accuracy Best Classifier =  0.9311377245508982\n"
     ]
    }
   ],
   "source": [
    "fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('News_dataset.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(file['Content_Parsed'], \n",
    "                                                    file['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = [175,200,250]\n",
    "path = ['max_features/175','max_features/200','max_features/250']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features/175\n",
      "(1891, 175)\n",
      "(334, 175)\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        81\n",
      "           1       0.87      0.98      0.92        49\n",
      "           2       0.94      0.85      0.89        72\n",
      "           3       0.99      0.96      0.97        72\n",
      "           4       0.91      0.87      0.89        60\n",
      "\n",
      "    accuracy                           0.92       334\n",
      "   macro avg       0.92      0.92      0.92       334\n",
      "weighted avg       0.92      0.92      0.92       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9101796407185628\n",
      "Accuracy Best Classifier =  0.9161676646706587\n",
      "\n",
      "max_features/200\n",
      "(1891, 200)\n",
      "(334, 200)\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        81\n",
      "           1       0.87      0.96      0.91        49\n",
      "           2       0.94      0.86      0.90        72\n",
      "           3       0.99      0.99      0.99        72\n",
      "           4       0.93      0.87      0.90        60\n",
      "\n",
      "    accuracy                           0.92       334\n",
      "   macro avg       0.92      0.92      0.92       334\n",
      "weighted avg       0.92      0.92      0.92       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9191616766467066\n",
      "Accuracy Best Classifier =  0.9221556886227545\n",
      "\n",
      "max_features/250\n",
      "(1891, 250)\n",
      "(334, 250)\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        81\n",
      "           1       0.92      0.96      0.94        49\n",
      "           2       0.94      0.88      0.91        72\n",
      "           3       0.99      0.97      0.98        72\n",
      "           4       0.93      0.92      0.92        60\n",
      "\n",
      "    accuracy                           0.93       334\n",
      "   macro avg       0.93      0.93      0.93       334\n",
      "weighted avg       0.93      0.93      0.93       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9311377245508982\n",
      "Accuracy Best Classifier =  0.9311377245508982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(path)):\n",
    "    print(path[i])\n",
    "    features_train, labels_train, features_test, labels_test = tf_idf(ngram_range, min_df, max_df, max_features[i], path[i])\n",
    "    fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use in Logistic Regression:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': 8,\n",
      " 'solver': 'lbfgs',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'multinomial', 'class_weight': None, 'C': 1.7}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9508179676166998\n",
      "\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "The best hyperparameters from Grid Search are:\n",
      "{'C': 1.9, 'class_weight': None, 'multi_class': 'multinomial', 'solver': 'lbfgs'}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9626666666666667\n",
      "\n",
      "LogisticRegression(C=1.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=8, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "choice = 1\n",
    "best_classifier = crossVal(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        81\n",
      "           1       0.92      0.96      0.94        49\n",
      "           2       0.97      0.89      0.93        72\n",
      "           3       0.97      0.99      0.98        72\n",
      "           4       0.93      0.92      0.92        60\n",
      "\n",
      "    accuracy                           0.94       334\n",
      "   macro avg       0.94      0.94      0.94       334\n",
      "weighted avg       0.94      0.94      0.94       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9281437125748503\n",
      "Accuracy Best Classifier =  0.9431137724550899\n"
     ]
    }
   ],
   "source": [
    "features_train, labels_train, features_test, labels_test = featureLabelAwal()\n",
    "fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use in Random Forest:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 8,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9434181068095491\n",
      "\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   45.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'bootstrap': False, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.9434666666666667\n",
      "\n",
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=100, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
      "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "choice = 5\n",
    "best_classifier = crossVal(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        81\n",
      "           1       0.92      0.92      0.92        49\n",
      "           2       0.97      0.88      0.92        72\n",
      "           3       0.99      0.96      0.97        72\n",
      "           4       0.95      0.93      0.94        60\n",
      "\n",
      "    accuracy                           0.93       334\n",
      "   macro avg       0.94      0.93      0.93       334\n",
      "weighted avg       0.93      0.93      0.93       334\n",
      "\n",
      "\n",
      "Accuracy Base Model =  0.9281437125748503\n",
      "Accuracy Best Classifier =  0.9311377245508982\n"
     ]
    }
   ],
   "source": [
    "features_train, labels_train, features_test, labels_test = featureLabelAwal()\n",
    "fitandperform(features_train, labels_train, features_test, labels_test, best_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
